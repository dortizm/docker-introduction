{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://lssds.aura-astronomy.org/winter_school/sites/default/files/sods_atfdds_header01.jpg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Orquestación de contenedores:\n",
    "\n",
    "La orquestación de contenedores en el contexto de Docker se refiere a la gestión y automatización de múltiples contenedores dentro de un entorno distribuido. Es un aspecto crucial de DevOps y despliegue de aplicaciones modernas, especialmente al tratar con aplicaciones a gran escala que están compuestas por varios microservicios o contenedores. Las herramientas de orquestación de contenedores ayudan a automatizar tareas como el despliegue, escalado, creación de redes, balanceo de carga y más, facilitando la gestión y el mantenimiento de aplicaciones complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![https://www.linkedin.com/pulse/top-10-container-orchestration-tools-sandeep-kumar-patel/](images/top10.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuál es la motivación para utilizar la orquestación de contenedores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La motivación para utilizar la orquestación de contenedores en Docker surge de la necesidad de gestionar y operar eficientemente aplicaciones complejas compuestas por múltiples contenedores. A medida que las aplicaciones crecen en escala y complejidad, la gestión manual se vuelve impráctica y propensa a errores. La orquestación de contenedores proporciona una solución al automatizar el despliegue, escalado, gestión y monitoreo de aplicaciones en contenedores. Aquí están las principales motivaciones para utilizar la orquestación de contenedores en Docker:\n",
    "\n",
    "1. **Escalabilidad:** La orquestación de contenedores permite que las aplicaciones se escalen dinámicamente según la demanda. A medida que aumenta el tráfico, nuevas instancias de contenedores pueden lanzarse automáticamente y, cuando la demanda disminuye, los contenedores en exceso pueden reducirse. Esto garantiza una utilización óptima de los recursos y capacidad de respuesta.\n",
    "\n",
    "2. **Alta Disponibilidad:** Las herramientas de orquestación distribuyen contenedores en varios nodos, asegurando que si un nodo o contenedor falla, la aplicación permanezca operativa al reprogramar los contenedores en nodos saludables. Esto mejora la disponibilidad y minimiza el tiempo de inactividad.\n",
    "\n",
    "3. **Utilización Eficiente de Recursos:** Las plataformas de orquestación optimizan la asignación de recursos al programar la ejecución de contenedores en nodos con recursos disponibles. Esto evita el desperdicio de recursos y maximiza la utilización del hardware.\n",
    "\n",
    "4. **Despliegue Simplificado:** La orquestación de contenedores automatiza el proceso de despliegue, lo que permite una implementación consistente y confiable de aplicaciones en diferentes entornos. Esto reduce los errores humanos y acelera la canalización de despliegue.\n",
    "\n",
    "5. **Balanceo de Cargas:** Las herramientas de orquestación proporcionan mecanismos integrados de balanceo de cargas que distribuyen el tráfico entrante entre contenedores saludables. Esto garantiza una distribución uniforme de las solicitudes y evita la sobrecarga en contenedores específicos.\n",
    "\n",
    "6. **Autoreparación:** Las plataformas de orquestación monitorean continuamente la salud de los contenedores. Si un contenedor se vuelve insalubre o falla, el sistema de orquestación lo reemplaza automáticamente por una nueva instancia. Esto mantiene la disponibilidad de la aplicación.\n",
    "\n",
    "7. **Actualizaciones Graduales y Reversiones:** La orquestación simplifica el proceso de actualización de aplicaciones al permitir actualizaciones graduales, donde las nuevas versiones se implementan gradualmente, garantizando actualizaciones sin tiempo de inactividad. Si surgen problemas, es posible realizar reversiones de manera sencilla.\n",
    "\n",
    "8. **Descubrimiento de Servicios:** Dado que los contenedores se crean y destruyen de manera dinámica, los sistemas de orquestación proporcionan mecanismos de descubrimiento de servicios que facilitan que los contenedores se localicen y se comuniquen entre sí.\n",
    "\n",
    "9. **Entorno Consistente:** Las herramientas de orquestación garantizan que el entorno para cada contenedor sea consistente en todo el clúster, desde la configuración hasta las dependencias de software. Esto elimina inconsistencias que pueden llevar a fallos en la aplicación.\n",
    "\n",
    "10. **Agnosticismo de Infraestructura:** Las plataformas de orquestación abstraen la infraestructura subyacente, lo que permite que las aplicaciones se ejecuten sin problemas en varios proveedores de nube o entornos locales sin modificaciones.\n",
    "\n",
    "11. **Políticas de Escalado Automatizado:** Las plataformas de orquestación permiten establecer políticas de escalado automatizado basadas en métricas como el uso de la CPU o el consumo de memoria. Esto garantiza que la aplicación escale hacia arriba o hacia abajo según reglas predefinidas.\n",
    "\n",
    "12. **Seguridad:** Los sistemas de orquestación ofrecen características de seguridad como segmentación de redes, controles de acceso y gestión de secretos para proteger aplicaciones en contenedores.\n",
    "\n",
    "13. **Prácticas de DevOps:** La orquestación de contenedores se integra bien con las prácticas de DevOps, permitiendo la integración continua, el despliegue continuo y las metodologías de infraestructura como código (IaC).\n",
    "\n",
    "En esencia, la motivación para utilizar la orquestación de contenedores en Docker radica en abordar los desafíos de gestionar aplicaciones complejas a gran escala. Empodera a las organizaciones para lograr una mejor utilización de recursos, una mayor disponibilidad, implementaciones eficientes y una mejora en la colaboración entre los equipos de desarrollo y operaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. La orquestación de contenedores en Docker implica:\n",
    "___\n",
    "\n",
    "\n",
    "1. **Automatización del Despliegue:** Las herramientas de orquestación automatizan el proceso de implementación de aplicaciones en contenedores en un clúster de máquinas. Gestionan el despliegue de contenedores para garantizar que se estén ejecutando y sean saludables el número deseado de réplicas.\n",
    "\n",
    "2. **Escalabilidad:** La orquestación permite escalar horizontalmente tu aplicación mediante la adición o eliminación de instancias de contenedores según fluctúe la demanda. Esto se hace automáticamente según reglas predefinidas o métricas.\n",
    "\n",
    "3. **Balanceo de Cargas:** Las herramientas de orquestación distribuyen el tráfico entrante entre múltiples instancias de contenedores para garantizar una distribución uniforme y el uso eficiente de los recursos.\n",
    "\n",
    "4. **Descubrimiento de Servicios:** Dado que los contenedores se crean y destruyen de manera dinámica, las herramientas de orquestación ayudan a mantener un registro central de los servicios en ejecución y sus contenedores asociados. Esto facilita el descubrimiento de servicios dentro del clúster.\n",
    "\n",
    "5. **Actualizaciones Graduales y Reversiones:** La orquestación simplifica el proceso de actualización de aplicaciones al implementar nuevas versiones de contenedores de manera gradual y garantizar actualizaciones sin tiempo de inactividad. En caso de problemas, facilita las reversiones de manera sencilla.\n",
    "\n",
    "6. **Alta Disponibilidad:** La orquestación garantiza alta disponibilidad al distribuir contenedores en varios nodos. Si un nodo falla, el sistema de orquestación automáticamente reprograma los contenedores en nodos saludables.\n",
    "\n",
    "7. **Redes:** Las herramientas de orquestación gestionan las redes de contenedores, asegurando que los contenedores puedan comunicarse entre sí dentro y entre nodos.\n",
    "\n",
    "8. **Gestión de Almacenamiento:** Algunas soluciones de orquestación proporcionan mecanismos para gestionar el almacenamiento persistente de contenedores, garantizando que los datos se retengan incluso cuando los contenedores sean reemplazados.\n",
    "\n",
    "9. **Verificación de la Salud y Autoreparación:** Las plataformas de orquestación monitorean continuamente la salud de los contenedores. Si un contenedor falla o se vuelve insalubre, el sistema de orquestación lo reemplaza automáticamente con una nueva instancia.\n",
    "\n",
    "10. **Gestión de la Configuración:** Las herramientas de orquestación pueden gestionar variables de entorno, secretos y otros ajustes de configuración para los contenedores, garantizando configuraciones consistentes en todo el clúster.\n",
    "\n",
    "11. **Seguridad:** Las herramientas de orquestación implementan medidas de seguridad como segmentación de redes, controles de acceso y cifrado para proteger las aplicaciones en contenedores.\n",
    "\n",
    "12. **Integración con CI/CD:** La orquestación suele integrarse en las canalizaciones de integración continua y despliegue continuo (CI/CD), automatizando el despliegue de nuevos cambios de código.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Algunas de las herramientas populares de orquestación de contenedores en Docker incluyen:\n",
    "\n",
    "- **[Kubernetes](https://kubernetes.io/):** Una plataforma de código abierto para automatizar el despliegue, escalado y gestión de aplicaciones en contenedores.\n",
    "\n",
    "- **[Docker Swarm](https://docs.docker.com/engine/swarm/):** Una solución de agrupación y orquestación nativa de Docker, diseñada para funcionar perfectamente con contenedores Docker.\n",
    "\n",
    "- **[Apache Mesos](https://mesos.apache.org/):** Un núcleo de sistemas distribuidos que abstrae la CPU, memoria, almacenamiento y otros recursos, permitiendo una utilización eficiente de los recursos en clústeres.\n",
    "\n",
    "**Resumen:** La orquestación de contenedores en Docker implica automatizar la gestión de aplicaciones en contenedores en un clúster de máquinas. Simplifica el despliegue, escalado, balanceo de cargas y otras tareas operativas, lo que facilita la gestión de aplicaciones complejas en entornos dinámicos y distribuidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Desplegando Servicios de Jupyter Notebook con Docker Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a repasar un ejemplo de cómo podrías utilizar Docker Swarm para desplegar instancias de Jupyter Notebook para análisis de datos y programación colaborativa. En este escenario, configuraremos un clúster de Docker Swarm y desplegaremos servicios de Jupyter Notebook para varios usuarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Inicialización:** En primer lugar, deberás inicializar un Docker Swarm en una máquina anfitriona. Puedes hacerlo utilizando el comando `docker swarm init`. Esta máquina se convertirá en el administrador del Swarm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node left the swarm.\n"
     ]
    }
   ],
   "source": [
    "!docker swarm leave --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swarm initialized: current node (osb5cb8e7acrxsjh2xzbft1l6) is now a manager.\n",
      "\n",
      "To add a worker to this swarm, run the following command:\n",
      "\n",
      "    docker swarm join --token SWMTKN-1-1i0mzeh86lxtkgt1e0ko9mmmpkwrtmcrpkcx8m96sbla4tama3-blfc5zzakz06xl7mpst4fbzn7 192.168.65.4:2377\n",
      "\n",
      "To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!docker swarm init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Crear una Red de Superposición (Overlay Network):**\n",
    "   Crea una red de superposición para permitir la comunicación entre servicios. Ejecuta:\n",
    "   ```bash\n",
    "   docker network create --driver overlay jupyter_network\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s9u4zdk93odr5ax1dlf6xnh84\n"
     ]
    }
   ],
   "source": [
    "!docker network create --driver overlay jupyter_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Deploy Jupyter Notebook Service:**\n",
    "   You'll need a Docker image that includes Jupyter Notebook and any required libraries. Let's assume you have this image named `jupyter-image`. Deploy the Jupyter Notebook service using the following command:\n",
    "   ```bash\n",
    "   docker service create --name jupyter --network jupyter_network -p 8888:8888 jupyter-image\n",
    "   ```\n",
    "   This creates a Jupyter service named `jupyter` that runs on port 8888 and is connected to the `jupyter_network`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image jupyter_server:latest could not be accessed on a registry to record\n",
      "its digest. Each node will access jupyter_server:latest independently,\n",
      "possibly leading to different nodes running different\n",
      "versions of the image.\n",
      "\n",
      "u7rh6divxjwpfqw9en70qdkd3\n",
      "\n",
      "\u001b[1Ball progress: 0 out of 1 tasks \n",
      "\u001b[2Ball progress: 1 out of 1 tasks \u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "\u001b[1Bfy: Service converged to verify that tasks are stable... \u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!docker service create --name jupyter --network jupyter_network --publish published=8888,target=8888  jupyter_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                   COMMAND                  CREATED          STATUS                    PORTS                    NAMES\n",
      "6b48d522c849   jupyter_server:latest   \"tini -g -- jupyter …\"   25 seconds ago   Up 24 seconds (healthy)   8888-8889/tcp            jupyter.1.v1i8d2up9ips47goq68lw2a1l\n",
      "6cd39c060cb6   daskdev/dask:latest     \"tini -g -- /usr/bin…\"   11 minutes ago   Up 8 minutes              0.0.0.0:8786->8786/tcp   dask-cluster-scheduler-1\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. **Scaling the Service:**\n",
    "   As more users require Jupyter Notebook instances, you can scale the service:\n",
    "   ```bash\n",
    "   docker service scale jupyter=3\n",
    "   ```\n",
    "   This command scales the `jupyter` service to have three replicas, allowing three users to run Jupyter Notebook instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter scaled to 3\n",
      "\n",
      "\u001b[1Ball progress: 0 out of 3 tasks \n",
      "\u001b[1B   K\n",
      "\u001b[1B   K\n",
      "\u001b[4Ball progress: 3 out of 3 tasks \u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[2A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "\u001b[1Bfy: Service converged to verify that tasks are stable... \u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!docker service scale jupyter=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                   COMMAND                  CREATED              STATUS                        PORTS                    NAMES\n",
      "92a9d71e520d   jupyter_server:latest   \"tini -g -- jupyter …\"   19 seconds ago       Up 17 seconds (healthy)       8888-8889/tcp            jupyter.2.c0wm1dx3vsdxtpukqknxmok13\n",
      "4b8c38b6f6a6   jupyter_server:latest   \"tini -g -- jupyter …\"   19 seconds ago       Up 17 seconds (healthy)       8888-8889/tcp            jupyter.3.okpbynna22g6krzunc2yqimtc\n",
      "6b48d522c849   jupyter_server:latest   \"tini -g -- jupyter …\"   About a minute ago   Up About a minute (healthy)   8888-8889/tcp            jupyter.1.v1i8d2up9ips47goq68lw2a1l\n",
      "6cd39c060cb6   daskdev/dask:latest     \"tini -g -- /usr/bin…\"   11 minutes ago       Up 9 minutes                  0.0.0.0:8786->8786/tcp   dask-cluster-scheduler-1\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Balanceo de Carga:**\n",
    "   Docker Swarm distribuye automáticamente el tráfico entrante a las réplicas del servicio `jupyter`, proporcionando balanceo de carga."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Persistencia de Datos:**\n",
    "   Para garantizar la persistencia de datos, puedes montar un volumen en el contenedor de Jupyter Notebook. De esta manera, los datos de los usuarios se conservarán aunque se reemplace un contenedor. Utiliza la bandera `-v` al crear el servicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. **Actualización de Servicios:**\n",
    "   Si necesitas actualizar la imagen de Jupyter Notebook con nuevas bibliotecas o características, puedes hacerlo construyendo una nueva imagen y actualizando el servicio:\n",
    "   ```bash\n",
    "   docker service update --image nueva-imagen-jupyter jupyter\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **Escalado y Gestión:**\n",
    "   Puedes seguir escalando el servicio `jupyter` según sea necesario para acomodar a más usuarios. Docker Swarm se encargará de gestionar la distribución de las instancias entre los nodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. **Alta Disponibilidad:**\n",
    "   Si un nodo experimenta una falla, Docker Swarm garantizará que el servicio siga funcionando al reprogramar las réplicas en nodos saludables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. **Eliminación de Servicios:**\n",
    "    Cuando hayas terminado, puedes eliminar el servicio `jupyter` y la red de superposición utilizando los comandos `docker service rm` y `docker network rm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter\n"
     ]
    }
   ],
   "source": [
    "!docker service rm jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker service create \\\n",
    "  --publish mode=host,target=80,published=8080 \\\n",
    "  --name=nginx \\\n",
    "  nginx:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al utilizar Docker Swarm para desplegar instancias de Jupyter Notebook, puedes proporcionar un entorno colaborativo para el análisis de datos y la programación. Las características de orquestación de Docker Swarm simplifican la gestión de los servicios de Jupyter, garantizando escalabilidad, balanceo de carga y alta disponibilidad para tus usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
