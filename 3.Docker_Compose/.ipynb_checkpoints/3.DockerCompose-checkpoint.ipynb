{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://lssds.aura-astronomy.org/winter_school/sites/default/files/sods_atfdds_header01.jpg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introducción a Docker Compose:\n",
    "\n",
    "Docker Compose es una herramienta que te permite definir y gestionar aplicaciones Docker de múltiples contenedores. Te permite describir la pila completa de la aplicación, incluyendo múltiples servicios, redes y volúmenes, en un único archivo YAML. Esta introducción teórica te ayudará a comprender los conceptos fundamentales de Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tcude.net/content/images/2022/01/MainImage-2.jpeg\" alt=\"La Serena School for Data Science: Applied Tools for Data-driven Sciences\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Simplificando las Aplicaciones de Múltiples Contenedores:\n",
    "---\n",
    "\n",
    "- Muchas aplicaciones modernas están compuestas por varios servicios, cada uno ejecutándose en su propio contenedor. Estos servicios a menudo necesitan comunicarse e interactuar entre sí.\n",
    "- Docker Compose simplifica el proceso de gestionar y coordinar estas aplicaciones de múltiples contenedores al permitirte definir y controlar toda la pila con un único archivo de configuración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Archivo YAML de Docker Compose:\n",
    "___\n",
    "\n",
    "- Se utiliza un archivo YAML de Docker Compose (***docker-compose.yml***) para definir los componentes de una aplicación de múltiples contenedores. Especifica servicios, redes, volúmenes y otras configuraciones.\n",
    "- El archivo YAML es legible por humanos y te permite definir las relaciones, dependencias y ajustes para cada servicio en la pila de tu aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Servicios:\n",
    "___\n",
    "- Un servicio es una unidad de una aplicación definida en el archivo YAML de Docker Compose. Corresponde a un contenedor y define cómo debe configurarse y ejecutarse el contenedor.\n",
    "- Cada servicio en el archivo ***docker-compose.yml*** puede tener su propia imagen, variables de entorno, puertos, volúmenes y otras configuraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Redes:\n",
    "___\n",
    "- Docker Compose te permite crear redes personalizadas para tus servicios. Las redes permiten la comunicación entre servicios al mismo tiempo que los aíslan del tráfico externo.\n",
    "- Los servicios dentro de la misma red pueden comunicarse utilizando los nombres de los servicios como nombres de host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Volúmenes:\n",
    "___\n",
    "- Los volúmenes en Docker Compose te permiten persistir y compartir datos entre contenedores. Se utilizan para almacenar datos que deben persistir más allá del ciclo de vida del contenedor.\n",
    "- Los volúmenes son especialmente útiles para contenedores de bases de datos o contenedores con archivos de configuración importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Ventajas de Docker Compose:\n",
    "___\n",
    "- **Simplicidad:** Docker Compose abstrae la complejidad de gestionar múltiples contenedores, facilitando la definición y el mantenimiento de pilas de aplicaciones complejas.\n",
    "- **Reproducibilidad:** Con un único archivo docker-compose.yml, puedes definir toda la pila de la aplicación, garantizando la consistencia en diferentes entornos.\n",
    "- **Portabilidad:** Las configuraciones de Docker Compose pueden ser versionadas y compartidas, lo que permite a los equipos colaborar y asegurarse de que la misma aplicación se ejecute de manera consistente en todas partes.\n",
    "- **Aislamiento:** Los servicios en Docker Compose se ejecutan en contenedores aislados, proporcionando un aislamiento a nivel de proceso mientras permiten una comunicación fluida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Casos de Uso:\n",
    "___\n",
    "- Docker Compose es especialmente útil para entornos de desarrollo y pruebas, donde necesitas crear rápidamente toda una pila de aplicaciones para pruebas locales o depuración.\n",
    "- También es valioso para crear configuraciones repetibles en pipelines de integración continua y despliegue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Verificación de la Instalación de Docker Compose:\n",
    "___\n",
    "Después de instalar Docker Desktop, deberías tener Docker Compose disponible automáticamente. Para verificar la instalación, abre una terminal y ejecuta el siguiente comando:\n",
    "\n",
    "```bash\n",
    "docker-compose --version\n",
    "```\n",
    "\n",
    "Este comando mostrará la versión de Docker Compose instalada si la instalación fue exitosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker Compose version v2.17.2\n"
     ]
    }
   ],
   "source": [
    "!docker-compose --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen:\n",
    "___\n",
    "Docker Compose simplifica la gestión de aplicaciones de múltiples contenedores al proporcionar una manera declarativa de definir y orquestar servicios, redes y volúmenes. Es una herramienta valiosa tanto para desarrolladores como para equipos de DevOps, ya que permite optimizar el despliegue y prueba de aplicaciones complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ejecuta Tu Primer Contenedor de Docker:\n",
    "---\n",
    "\n",
    "### Paso 1: Crea un Directorio para tu Proyecto:\n",
    "Abre una terminal y crea un nuevo directorio para tu proyecto de clúster Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir dask-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd dask-cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Crea un Archivo docker-compose.yml:\n",
    "\n",
    "Dentro de tu directorio de proyecto, crea un archivo llamado **docker-compose.yml** utilizando un editor de texto de tu elección. Este archivo definirá la configuración de tu clúster Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Define Servicios en docker-compose.yml:\n",
    "\n",
    "Agrega el siguiente contenido a tu archivo docker-compose.yml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: '3'\n",
      "services:\n",
      "  scheduler:\n",
      "    image: daskdev/dask:latest\n",
      "    command: [\"dask-scheduler\"]\n",
      "    ports:\n",
      "      - \"8786:8786\"\n",
      "\n",
      "  worker:\n",
      "    image: daskdev/dask:latest\n",
      "    command: [\"dask-worker\", \"scheduler:8786\"]\n",
      "    depends_on:\n",
      "      - scheduler"
     ]
    }
   ],
   "source": [
    "!cat dask-cluster/docker-compose.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta configuración define dos servicios: **scheduler** y **worker**.\n",
    "\n",
    "- El servicio ***scheduler*** utiliza la imagen ***daskdev/dask*** y ejecuta el programador de Dask mediante el comando dask-scheduler. Expone el puerto 8786 para la comunicación.\n",
    "- El servicio ***worker*** también utiliza la misma imagen y ejecuta un worker de Dask mediante el comando ***dask-worker***. Depende del servicio ***scheduler*** y se conecta al puerto 8786 del programador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Inicia el Clúster Dask:\n",
    "\n",
    "En tu terminal, navega hasta el directorio de tu proyecto y ejecuta el siguiente comando para iniciar el clúster Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta el comando `docker-compose up` con la opción `-f` o `--file` seguida de la ruta hacia tu archivo docker-compose.yml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 2/0\n",
      " \u001b[32m✔\u001b[0m Container dask-cluster-scheduler-1  \u001b[32mCreated\u001b[0m                             \u001b[34m0.0s \u001b[0m\n",
      " \u001b[32m✔\u001b[0m Container dask-cluster-worker-1     \u001b[32mCreated\u001b[0m                             \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25hAttaching to dask-cluster-scheduler-1, dask-cluster-worker-1\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0mno environment.yml\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' == true ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ CONDA_BIN=/opt/conda/bin/conda\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' -e /opt/app/environment.yml ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ echo 'no environment.yml'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ '[' '' ']'\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m+ exec dask-scheduler\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0mno environment.yml\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' == true ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ CONDA_BIN=/opt/conda/bin/conda\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' -e /opt/app/environment.yml ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ echo 'no environment.yml'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ '[' '' ']'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m+ exec dask-worker scheduler:8786\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m/opt/conda/lib/python3.10/site-packages/distributed/cli/dask_scheduler.py:142: FutureWarning: dask-scheduler is deprecated and will be removed in a future release; use `dask scheduler` instead\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m  warnings.warn(\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,165 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m/opt/conda/lib/python3.10/site-packages/distributed/cli/dask_worker.py:266: FutureWarning: dask-worker is deprecated and will be removed in a future release; use `dask worker` instead\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m  warnings.warn(\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,624 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,672 - distributed.scheduler - INFO - State start\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,678 - distributed.scheduler - INFO - -----------------------------------------------\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,679 - distributed.scheduler - INFO -   Scheduler at:     tcp://172.22.0.2:8786\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:12,680 - distributed.scheduler - INFO -   dashboard at:  http://172.22.0.2:8787/status\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:12,698 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.22.0.3:35295'\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -       Start worker at:     tcp://172.22.0.3:34997\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -          Listening to:     tcp://172.22.0.3:34997\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO -          dashboard at:           172.22.0.3:36379\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO - Waiting to connect to:       tcp://scheduler:8786\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,639 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -               Threads:                          4\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -                Memory:                   7.68 GiB\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r4mya_7x\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:13,640 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,142 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://172.22.0.3:34997', status: init, memory: 0, processing: 0>\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,583 - distributed.scheduler - INFO - Starting worker compute stream, tcp://172.22.0.3:34997\n",
      "\u001b[36mdask-cluster-scheduler-1  | \u001b[0m2023-08-12 20:04:14,584 - distributed.core - INFO - Starting established connection to tcp://172.22.0.3:54926\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,584 - distributed.worker - INFO - Starting Worker plugin shuffle\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,585 - distributed.worker - INFO -         Registered to:       tcp://scheduler:8786\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,585 - distributed.worker - INFO - -------------------------------------------------\n",
      "\u001b[33mdask-cluster-worker-1     | \u001b[0m2023-08-12 20:04:14,587 - distributed.core - INFO - Starting established connection to tcp://scheduler:8786\n",
      "^C\n",
      "Gracefully stopping... (press Ctrl+C again to force)\n",
      "Aborting on container exit...\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 0/0\n",
      " ⠋ Container dask-cluster-worker-1  \u001b[39mS...\u001b[0m                                   \u001b[34m0.1s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker-compose -f dask-cluster/docker-compose.yml up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Compose will pull the necessary images and start the scheduler and worker containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 5: Verificar el clúster:\n",
    "\n",
    "Una vez que hayas ejecutado el comando `docker-compose up`, puedes comprobar el estado del clúster Dask visitando la dirección `http://localhost:8786` en tu navegador web. Esto te llevará al panel de control del clúster Dask, donde podrás supervisar y administrar tus trabajadores y tareas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 6: Detener el Clúster:\n",
    "\n",
    "Para detener el clúster Dask, presiona **Ctrl+C** en la terminal donde iniciaste el clúster con `docker-compose up`.\n",
    "\n",
    "### Paso 7: Limpiar:\n",
    "\n",
    "Si deseas eliminar los contenedores y la red creados por Docker Compose, ejecuta el siguiente comando en el directorio de tu proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configuration file provided: not found\n"
     ]
    }
   ],
   "source": [
    "!docker-compose down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen:\n",
    "¡Listo! Has creado una configuración de Docker Compose para un clúster Dask en Python. Esta configuración te permite gestionar y escalar fácilmente tu clúster Dask para tareas de cómputo distribuido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
